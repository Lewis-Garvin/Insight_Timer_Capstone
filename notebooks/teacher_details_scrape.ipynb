{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4247be46",
   "metadata": {},
   "source": [
    "# Teacher Details Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f52147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight Timer webpages use javascript, so need selenium and chrome driver.\n",
    "chrome_driver_path = '../../../../Tech/chrome_driver/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126fc437",
   "metadata": {},
   "source": [
    "### Function: Assign Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbad60",
   "metadata": {},
   "source": [
    "Assumptions/Requirements for function:\n",
    "- The Teachers List Scraping notebook has been run successfully, creating the teachers_list_df.csv file.\n",
    "- Teachers_list_df.csv has numeric sequential index values starting with 0.\n",
    "- The batch_size argument passed to the function is an integer value between 0 and the number of rows in teachers_list_df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1c0ef",
   "metadata": {},
   "source": [
    "***Note: Once you choose a batch size, you want to avoid reassigning batches with a different batch size. If you do reassign with a different batch size, you can redo it with the original batch size and it will be the same as it was before.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c49598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_batches(batch_size):\n",
    "    teachers_list_df = pd.read_csv('../data/teachers_list_df.csv', index_col=0)\n",
    "    \n",
    "    num_rows = teachers_list_df.shape[0]    \n",
    "    \n",
    "    #Verify that the index values are as expected (0, 1, 2, etc.)\n",
    "    index_list = teachers_list_df.index.to_list()\n",
    "    for x in list(range(0,num_rows)):\n",
    "        assert index_list[x] == x\n",
    "\n",
    "    print(num_rows,'total rows')\n",
    "    print(batch_size,'rows per batch')\n",
    "    num_batches = ((num_rows - (num_rows % batch_size)) / batch_size) + min(1,num_rows % batch_size)\n",
    "    print(int(num_batches),'batches')\n",
    "\n",
    "    #perhaps incorporate divmod()\n",
    "    \n",
    "    for index, row in teachers_list_df.iterrows():\n",
    "        teachers_list_df.loc[index, 'batch_id'] = ((index - (index % batch_size)) / batch_size) + 1\n",
    "\n",
    "    teachers_list_df.batch_id = teachers_list_df.batch_id.astype('int')\n",
    "    \n",
    "    #Save batch results to data file\n",
    "    teachers_list_df.to_csv('../data/teachers_batch_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f1bca",
   "metadata": {},
   "source": [
    "### Function: Scrape Teachers One Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea37fe",
   "metadata": {},
   "source": [
    "Assumptions/Requirements for function:\n",
    "- The assign_batches function has been run to create the teachers_batch_list.csv file.\n",
    "- Dataframe teachers_batch_list has been created by reading in teachers_batch_list.csv file.\n",
    "- Teachers_batch_list has numeric sequential index values starting with 0.\n",
    "- The scrape_batch_id argument passed to the function is an integer that matches an index value for a row in teachers_batch_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2249847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_teachers_one_batch(scrape_batch_id):\n",
    "    teachers_batch = teachers_batch_list.copy().loc[teachers_batch_list.batch_id == scrape_batch_id]\n",
    "    print(teachers_batch.shape[0],'rows in batch')\n",
    "    \n",
    "    #Batch Start\n",
    "    batch_start_time = datetime.now()\n",
    "    batch_row = 0\n",
    "\n",
    "    for index, row in teachers_batch.iterrows():\n",
    "        batch_row += 1\n",
    "        print('Batch row',batch_row,'of',teachers_batch.shape[0],': teacher_id =', row.teacher_id)\n",
    "\n",
    "        #Record scrape date (Rows will have scrape_date even if page not found.)\n",
    "        teachers_batch.loc[index, 'scrape_date'] = date.today()\n",
    "\n",
    "        teacher_url = 'https://insighttimer.com/' + row.teacher_id\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "        driver.get(teacher_url)\n",
    "\n",
    "        #Wait for page to fully load\n",
    "        driver.implicitly_wait(2)  #Two seconds is usually but not always long enough.\n",
    "        \n",
    "        #Make soup\n",
    "        soup = BS(driver.page_source)\n",
    "        \n",
    "#        if driver.getPageSource().contains(\"The page you were looking for doesn't exist.\"):\n",
    "#        print(type(driver.page_source))\n",
    "#        if driver.page_source.contains(\"The page you were looking for doesn't exist.\"):\n",
    "#<h1 class=\"text-lg font-ProxiBold mb-6 leading-tight\">The page you were looking for doesn't exist.</h1>\n",
    "\n",
    "        h1_page_not_found_tag = soup.find('h1', attrs = {'class':'text-lg font-ProxiBold mb-6 leading-tight'})\n",
    "        if h1_page_not_found_tag is None:\n",
    "            page_found = True\n",
    "        elif h1_page_not_found_tag.text == \"The page you were looking for doesn't exist.\":\n",
    "            page_found = False\n",
    "        else:\n",
    "            page_found = True\n",
    "        \n",
    "        if page_found == False:\n",
    "            teachers_batch.loc[index, 'scrape_status'] = 'page not found'\n",
    "            print('PAGE NOT FOUND for teacher_id =',row.teacher_id)\n",
    "            driver.close() #Close driver (closes browser window)\n",
    "\n",
    "        else:\n",
    "            #Get teacher_name. If not found, wait longer, remake soup, and look again.\n",
    "            h2_name_tag = soup.find('h2', attrs = {'class':'chakra-text css-nagewt'})\n",
    "        \n",
    "            if h2_name_tag is None:\n",
    "                driver.implicitly_wait(5)\n",
    "                soup = BS(driver.page_source)\n",
    "                h2_name_tag = soup.find('h2', attrs = {'class':'chakra-text css-nagewt'})\n",
    "\n",
    "            driver.close() #Close driver (closes browser window)\n",
    "            \n",
    "            if h2_name_tag is None:\n",
    "                teachers_batch.loc[index, 'scrape_status'] = 'name not found'\n",
    "                print('Teacher name not found for teacher_id =',\n",
    "                      row.teacher_id, \n",
    "                      'in batch_id = ',\n",
    "                      scrape_batch_id)\n",
    "            else:\n",
    "                teachers_batch.loc[index, 'scrape_status'] = 'name found'\n",
    "                teachers_batch.loc[index, 'teacher_name'] = h2_name_tag.text\n",
    "\n",
    "                \n",
    "            #Get location\n",
    "            p_location_tag = soup.find('p', attrs = {'class':'chakra-text css-1n5ydt0'})\n",
    "            if p_location_tag is not None:    \n",
    "                teachers_batch.loc[index, 'location'] = p_location_tag.text\n",
    "\n",
    "            #Get followers\n",
    "            p_followers_tag = soup.find('p', attrs = {'class':'chakra-text css-brfdt9'})\n",
    "            if p_followers_tag is not None:\n",
    "                teachers_batch.loc[index, 'followers'] = p_followers_tag.text\n",
    "\n",
    "            #Get languages\n",
    "            p_languages_tag = soup.find('p', attrs = {'class':'chakra-text css-1gmivde'})\n",
    "            if p_languages_tag is not None:\n",
    "                teachers_batch.loc[index, 'languages'] = p_languages_tag.text\n",
    "\n",
    "            #Get date joined\n",
    "            p_date_joined_tag = soup.find('p', attrs = {'class':'chakra-text css-d0wkpr'})\n",
    "            if p_date_joined_tag is not None:\n",
    "                teachers_batch.loc[index, 'date_joined'] = p_date_joined_tag.text    \n",
    "\n",
    "            #Get about text\n",
    "            div_about_tag = soup.find('div', attrs = {'class':'css-17179af'})\n",
    "            if div_about_tag is not None:\n",
    "                teachers_batch.loc[index, 'about'] = div_about_tag.text   \n",
    "\n",
    "            #Get image url\n",
    "            img_image_tag = soup.find('img', attrs = {'class':'chakra-image css-1ssn357'})\n",
    "            if img_image_tag is not None:\n",
    "                teachers_batch.loc[index, 'image_url'] = img_image_tag.get('src', default = '/no src')\n",
    "\n",
    "    #Save batch results to data file\n",
    "    batch_id_string = str(scrape_batch_id).zfill(5)  \n",
    "    #zfill adds leading zeros which allows filenames to be sorted correctly alphabetically.\n",
    "    batch_filename = '../data/teacher_batch_files/teacher_batch_' + str(batch_id_string) + '.csv'\n",
    "    teachers_batch.to_csv(batch_filename)\n",
    "\n",
    "    #Batch End\n",
    "    batch_end_time = datetime.now()\n",
    "\n",
    "    #Print Runtime \n",
    "    batch_runtime = batch_end_time - batch_start_time\n",
    "    hours, remainder = divmod(batch_runtime.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print('Batch_id',scrape_batch_id,'completed')\n",
    "    print('Batch runtime:')\n",
    "\n",
    "    if hours > 0:\n",
    "        print(hours,'hours')\n",
    "    if minutes > 0:\n",
    "        print(minutes,'minutes')\n",
    "    print(seconds,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d0c25",
   "metadata": {},
   "source": [
    "### Scrape Multiple Teacher Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_teachers_multiple_batches(batch_id_range_or_list):\n",
    "    if type(batch_id_range_or_list) == type(range(0,2)):\n",
    "        batch_id_list = list(batch_id_range_or_list)\n",
    "    elif type(batch_id_range_or_list) == type([0, 1]):\n",
    "        batch_id_list = batch_id_range_or_list\n",
    "    else:\n",
    "        print('ERROR Wrote datatype')\n",
    "    \n",
    "    teachers_batch_list = pd.read_csv('../data/teachers_batch_list.csv', index_col=0)\n",
    "    \n",
    "    #Verify that the index values are as expected (0, 1, 2, etc.)\n",
    "    index_list = teachers_batch_list.index.to_list()\n",
    "    for x in list(range(0,teachers_batch_list.shape[0])):\n",
    "        assert index_list[x] == x\n",
    "    \n",
    "    #Start Batches\n",
    "    batches_start_time = datetime.now()\n",
    "    batch_num = 0\n",
    "    \n",
    "    for batch_id in batch_id_list:\n",
    "        batch_num += 1\n",
    "        print('Starting batch', \n",
    "              batch_num,\n",
    "              'out of',\n",
    "              len(batch_id_list),\n",
    "              ', batch_id =',\n",
    "              batch_id)\n",
    "        scrape_teachers_one_batch(batch_id)\n",
    "        print('Completed batch_id = ',batch_id)\n",
    "        print('')\n",
    "        \n",
    "    #End Batches\n",
    "    batches_end_time = datetime.now()\n",
    "\n",
    "    #Print Runtime \n",
    "    batches_runtime = batches_end_time - batches_start_time\n",
    "    hours, remainder = divmod(batches_runtime.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print(batch_num,'batches completed with runtime:')\n",
    "    if hours > 0:\n",
    "        print(hours,'hours')\n",
    "    if minutes > 0:\n",
    "        print(minutes,'minutes')\n",
    "    print(seconds,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b6e7c",
   "metadata": {},
   "source": [
    "### Example use of assign_batches function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "assign_batches(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a9826",
   "metadata": {},
   "source": [
    "### Example use of scrape_teachers_one_batch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f248c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "teachers_batch_list = pd.read_csv('../data/teachers_batch_list.csv', index_col=0)\n",
    "\n",
    "#Verify that the index values are as expected (0, 1, 2, etc.)\n",
    "index_list = teachers_batch_list.index.to_list()\n",
    "for x in list(range(0,teachers_batch_list.shape[0])):\n",
    "    assert index_list[x] == x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_batch_id = 576\n",
    "scrape_teachers_one_batch(scrape_batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_batch = pd.read_csv('../data/teacher_batch_files/teacher_batch_00576.csv', index_col=0)\n",
    "fresh_batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa97c67",
   "metadata": {},
   "source": [
    "### Example Use of scrape_teachers_multiple_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bc4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_id_range_or_list = range(134, 137)\n",
    "scrape_teachers_multiple_batches(batch_id_range_or_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0928c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch134 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00134.csv', index_col=0)\n",
    "batch135 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00135.csv', index_col=0)\n",
    "batch136 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00136.csv', index_col=0)\n",
    "\n",
    "batch_df_list = [batch134, batch135, batch136]\n",
    "batches_range_result = pd.concat(batch_df_list)\n",
    "batches_range_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39708ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Example Use of scrape_teachers_multiple_batches\n",
    "batch_id_range_or_list = [101, 102, 876]\n",
    "scrape_teachers_multiple_batches(batch_id_range_or_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch101 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00101.csv', index_col=0)\n",
    "batch102 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00102.csv', index_col=0)\n",
    "batch876 = pd.read_csv('../data/teacher_batch_files/teacher_batch_00876.csv', index_col=0)\n",
    "\n",
    "batch_df_list = [batch101, batch102, batch876]\n",
    "batches_list_result = pd.concat(batch_df_list)\n",
    "batches_list_result.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
